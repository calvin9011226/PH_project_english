import logging
from datetime import datetime
import os
import json
import time
import re
import pandas as pd
from collections import defaultdict
import matplotlib.pyplot as plt
from matplotlib.patches import Patch
from matplotlib import cm
from matplotlib.ticker import MultipleLocator
import psutil                           #å–å¾—é›»è…¦è³‡æºå ç”¨å¥—ä»¶
from threading import Thread
import matplotlib.dates as mdates
import glob

#è®“pltå¯ä»¥é¡¯ç¤ºä¸­æ–‡
plt.rcParams["font.family"] = "Microsoft JhengHei"   # æˆ–ä½ æ©Ÿå™¨çœŸçš„æœ‰çš„å­—å‹
plt.rcParams["axes.unicode_minus"] = False           # è®“è² è™Ÿä¹Ÿæ­£å¸¸

#å…¬ç‰ˆå­—å‹
Default_font = {
    "x_label": 16,
    "y_label": 16,
    "x_ticks": 14,
    "y_ticks": 14,
    "title": 20,
    "legend_title": 13,
    "legend_content": 15,
    "value_text": 12,
    "colorbar_label": 16,
    "colorbar_ticks": 14
}

#--------------------------------------ç•«åœ–å‡½æ•¸--------------------------------------------------

#çµ±è¨ˆæ™‚é–“åœ–
def plot_bar(
    labels,             # list: y è»¸é …ç›®åç¨±ï¼ˆå·²åœ¨å¤–é¢æ’å¥½åºï¼‰
    values,             # list or list of lists: å°æ‡‰ label çš„æ•°å€¼
    save_path,          # str: åœ–ç‰‡å„²å­˜è·¯å¾‘
    title="",           # str: æ¨™é¡Œ
    xlabel="Time (s)",  # str: X è»¸æ¨™ç±¤
    is_stacked=False,   # bool: æ˜¯å¦å †å 
    colors=None,        # list: bar é¡è‰²
    sub_colors=None,    # dict: å­åŠŸèƒ½â†’å°æ‡‰é¡è‰²
    data_sizes=None,    # dict: labelâ†’å¤§å°
    show_times=True,    # bool: æ˜¯å¦é¡¯ç¤ºå­åŠŸèƒ½çš„è€—æ™‚
    longest_time=40,    # æ™‚é–“æœ€é•·çš„é‚£ä¸€æ®µ
    tick_interval=None, # æ±ºå®šæ¯å€‹æ™‚é–“é–“éš”
    fixed_xlim=None,    # æ±ºå®šç¸½æ™‚é•·
    size_off=False,     # æ˜¯å¦è¦å°å‡º
    font_config=None,
):
    #å­—é«”å¤§å°è¨­å®šåƒæ•¸

    data_fontsize=12
    config = {**Default_font, **(font_config or {})}

    fig, ax = plt.subplots(figsize=(12, max(4, len(labels)*0.7)))
    y_pos = range(len(labels))  
        # è¨­å®š x è»¸æœ€å¤§å€¼
    if fixed_xlim:
        ax.set_xlim(0, fixed_xlim)
        longest_time=fixed_xlim
    else:
        ax.set_xlim(0, longest_time * 1.1)

    min_width = longest_time/150  # æœ€å°å¯è¦–å¯¬åº¦ï¼ˆå–®ä½ï¼šç§’ï¼Œå¯è‡ªè¡Œèª¿æ•´ï¼‰

    # å¦‚æœå¤–é¢æ²’æœ‰å‚³ colorsï¼Œå°±è£œä¸€ä¸ªç©ºåˆ—è¡¨
    if colors is None:
        colors = [None] * len(labels)

    if is_stacked:
        # å †ç–Š bar
        
        for i, segment in enumerate(values):
            left = 0
            seg_colors = colors[i] or [None]*len(segment)

            for j, v in enumerate(segment):
                display_width = max(v, min_width)  # è‹¥ v å¤ªå°å°±ç•« min_width
                ax.barh(i, display_width, left=left, color=seg_colors[j], edgecolor='white')
                if show_times and v>min_width*8:
                    ax.text(left + display_width / 2, i, f"{v:.2f}s",
                            ha='center', va='center', fontsize=config["value_text"])
                left += display_width  # ç”¨ display_width å †ç–Š      

        # è³‡æ–™å¤§å°
        if data_sizes and  not size_off:
            for i, label in enumerate(labels):
                bar_len = sum(values[i])
                offset =ax.get_xlim()[1]*0.02           #è³‡æ–™å¤§å°çš„ä½ç§»é‡
                size = data_sizes.get(label, 0)
                ax.text(bar_len + offset, i, f"{size:.0f}B",
                        va='center', fontsize=data_fontsize)

        # åŠƒå‡ºæ¨™ç±¤
        if sub_colors:
            handles = [Patch(color=c, label=sub) for sub, c in sub_colors.items()]
#            ax.legend(handles=handles, title="Sub-function",loc='center left', bbox_to_anchor=(0.8235, 0.2105),
#                     fontsize=config["legend_content"],title_fontsize=config["legend_title"],prop={'weight': 'normal'},framealpha=0.9)
            ax.legend(handles=handles,loc='center left', bbox_to_anchor=(0.733, 0.247),prop={'size': config["legend_content"], 'weight': 'normal'}
                      ,framealpha=1,edgecolor='none')

    else:
        # æ™®é€šæ°´å¹³ bar
        bar_colors = colors
        ax.barh(y_pos, values, color=bar_colors)
        
        
        for i, v in enumerate(values):
            display_width = max(v, min_width)  # è‹¥ v å¤ªå°å°±ç•« min_width

            if show_times and v>min_width*10:
                ax.text(v/2, i, f"{v:.2f}s",
                        ha='center', va='center', fontsize=config["value_text"])
                
        # æ¨™è¨»ã€Œè³‡æ–™å¤§å°ã€
        if data_sizes and  not size_off:
            for i, label in enumerate(labels):
                bar_len = values[i]
                offset =ax.get_xlim()[1]*0.01           #è³‡æ–™å¤§å°çš„ä½ç§»é‡
                size = data_sizes.get(label, 0)
                ax.text(bar_len + offset, i, f"{size:.0f}B",va='center', 
                        fontsize=data_fontsize)

    # è¨­å®š x è»¸æœ€å¤§å€¼
    if tick_interval:
        ax.xaxis.set_major_locator(MultipleLocator(tick_interval))  # æ¯ 2 ç§’ä¸€æ ¼
        
    ax.set_yticks(y_pos)
    ax.set_yticklabels(labels,fontsize=config["y_label"])
    ax.set_xlabel(xlabel,fontsize=config["x_label"])
    ax.tick_params(axis='x', labelsize=config["x_ticks"])
    #ax.set_title(title,fontsize=16)
    fig.text(0.55, 0.06, title, ha='center', va='center', fontsize=config["title"])
    ax.grid(True, axis='x',color='gray', alpha=0.2)
    plt.tight_layout(pad=1.5,rect=[0, 0.1, 1, 1])
    plt.savefig(save_path, dpi=1000)
    plt.close()

#Pie Chartåœ“é¤…åœ–
def plot_pie(
    labels,                     # list: é …ç›®åç¨±
    values,                     # list: å°æ‡‰ label çš„æ•°å€¼
    save_path,                  # str:  åœ–ç‰‡å„²å­˜è·¯å¾‘
    title="",                   # str:  æ¨™é¡Œ
    label_type="",              # str:  labelæ¨™ç±¤çš„è³‡æ–™å–®ä½
    colors=None,                # list: bar é¡è‰²
    emphasize_num=0,             # int:  æŠŠå‰å¹¾å¤§çš„åœ“é¤…åœ–çªå‡º
    Values_Visible=True,        # bool: æ˜¯å¦è¦é¡¯ç¤ºæ•¸æ“š
    Percentage_Visible=True,    # bool: æ˜¯å¦è¦é¡¯ç¤ºç™¾åˆ†æ¯”
    font_config=None
):
    
    #åœ“é¤…åœ–å…§éƒ¨é¡¯ç¤ºçš„æ•¸å€¼ã€ç™¾åˆ†æ¯”
    inter_text = []
    total=sum(values)
    config = {**Default_font, **(font_config or {})}
    
    for value in values:
        parts = []
        if Values_Visible:
            parts.append(f"{value}")
        if Percentage_Visible:
            percent = (value / total) * 100
            parts.append(f"{percent:.1f}%")
        inter_text.append("\n".join(parts) if parts else "")

    def adjust_autopct(inter_text):
        def _autopct(pct):
            idx = _autopct.counter
            _autopct.counter += 1
            return inter_text[idx]
        _autopct.counter = 0
        return _autopct
    
    #æœ€å¤§çªå‡ºçš„éƒ¨åˆ†
    explode = []
    if emphasize_num==0:
        explode = [0] * len(values)
    else:    
        if emphasize_num>=len(values):
            emphasize_num=len(values)-1
            print(f"è¨­å®šçªå‡ºç›®æ¨™å·²è¶…æ¨™,ä»¥é™ä½è‡³{emphasize_num}å€‹")
        
        top_v = sorted(values, reverse=True)[:emphasize_num]
        for val in values:
            if val in top_v:
                explode.append(0.1)
            else:
                explode.append(0)

    #è‡ªå‹•é…è‰²
    if colors is None:
        cmap = plt.get_cmap("tab20", len(values))  # è‡ªå‹•æ ¹æ“š values æ•¸é‡é…è‰²
        colors = [cmap(i) for i in range(len(values))]

    fig, ax = plt.subplots()
    plt.pie(values, radius=3, labels=labels,autopct=adjust_autopct(inter_text),explode=explode,colors=colors)
    ax.axis('equal')
    ax.set_xlabel(label_type,fontsize=config["x_label"])
    plt.title(title, fontsize=config["title"])
    plt.tight_layout()
    plt.savefig(save_path, dpi=300)
    plt.close()

#æŠ˜ç·šåœ–
def plot_multiline_timeseries(
    time_index,
    data_dict,
    save_path="./plot.png",
    title="æŠ˜ç·šåœ–",
    xlabel="æ™‚é–“",
    ylabel="æ•¸å€¼",
    figsize=(12, 6),
    font_config=None,
    legend_config=None
):

    config = {**Default_font, **(font_config or {})}

    plt.figure(figsize=figsize)
    for tag, values in data_dict.items():
        plt.plot(time_index, values, marker='o', linestyle='-', label=tag)

    plt.tick_params(axis='x', labelsize=config["x_ticks"])
    plt.tick_params(axis='y', labelsize=config["y_ticks"])
    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%m/%d %H'))
    plt.gca().xaxis.set_major_locator(mdates.HourLocator(interval=1))
    plt.gcf().autofmt_xdate()
    plt.title(title, fontsize=config["title"])
    plt.xlabel(xlabel, fontsize=config["x_label"])
    plt.ylabel(ylabel, fontsize=config["y_label"])
    plt.legend(
        loc="upper left",
        bbox_to_anchor=(1, 1),
        prop=legend_config or {'size': config["legend_content"], 'weight': 'normal'}
    )
    plt.tight_layout(pad=1.5, rect=[0, 0, 1, 0.95])
    plt.grid(True)
    plt.savefig(save_path, dpi=300)
    plt.close()




#---------------------------------------- æ†å®šå€¼ ---------------------------------------------------
Unit_conversion={"B":1,"bytes":1,"Bytes":1,
                 "KB":1024      ,"kB":1024,
                 "MB":1048576   ,"mB":1048576,
                 "GB":1073741824,"gB":1073741824}

#------------------------------- feature mapping å®šç¾©å­—å…¸ -------------------------------------------
penghu_FM={
    "æ°¸çºŒè§€å…‰": "æ™¯é»æ¨è–¦",
    "ä¸€èˆ¬æ™¯é»æ¨è–¦": "æ™¯é»æ¨è–¦",
    "æ™¯é»æ¨è–¦": "æ™¯é»æ¨è–¦",
    "æ™¯é»äººæ½®": "æ™¯é»äººæ½®",
    "é™„è¿‘æœå°‹": "é™„è¿‘æœå°‹",
    "é¤å»³": "é™„è¿‘æœå°‹",
    "é¢¨æ™¯å€": "é™„è¿‘æœå°‹",
    "åœè»Šå ´": "é™„è¿‘æœå°‹",
    "ä½å®¿": "é™„è¿‘æœå°‹",
    "è¡Œç¨‹è¦åŠƒ": "è¡Œç¨‹è¦åŠƒ",
    "å…©å¤©ä¸€å¤œ": "è¡Œç¨‹è¦åŠƒ",
    "ä¸‰å¤©å…©å¤œ": "è¡Œç¨‹è¦åŠƒ",
    "å››å¤©ä¸‰å¤œ": "è¡Œç¨‹è¦åŠƒ",
    "äº”å¤©å››å¤œ": "è¡Œç¨‹è¦åŠƒ",
    "æ”¶é›†è³‡æ–™&ä¿®æ”¹è³‡æ–™": "æ”¶é›†è³‡æ–™&ä¿®æ”¹è³‡æ–™",
    "å¹´é½¡è¨­å®š": "æ”¶é›†è³‡æ–™&ä¿®æ”¹è³‡æ–™",
    "æ€§åˆ¥è¨­å®š": "æ”¶é›†è³‡æ–™&ä¿®æ”¹è³‡æ–™",
    "location": "æ”¶é›†è³‡æ–™&ä¿®æ”¹è³‡æ–™",
    "ç”·": "æ”¶é›†è³‡æ–™&ä¿®æ”¹è³‡æ–™",
    "å¥³": "æ”¶é›†è³‡æ–™&ä¿®æ”¹è³‡æ–™",
    "å…¶ä»–": "æ”¶é›†è³‡æ–™&ä¿®æ”¹è³‡æ–™",
    "ç§Ÿè»Š": "ç§Ÿè»Š"
}


#-------------------------------------- å…¬ç”¨å‡½æ•¸-----------------------------------------------------

def build_feature_mapping_from_log(
    log_path,                           # log æª”æ¡ˆè·¯å¾‘
    feature_mapping_style="auto",       # "penghu" ä½¿ç”¨é è¨­, "auto" å¾ log å»º, æˆ–å¤–éƒ¨å‚³å…¥ dict
    match_type="",                      # "Data Size", "Data Time", etc.
    predefined_mapping=None):           # å‚³å…¥ dictï¼ˆé penghu æ™‚ä½¿ç”¨ï¼‰

    # é è¨­ penghu æ¨¡å¼
    if feature_mapping_style == "penghu":
        return penghu_FM
    
    # è‡ªå‹•å¾ log å»ºç«‹
    elif feature_mapping_style == "auto":
        feature_mapping = {}
        with open(log_path, "r", encoding='utf-8-sig', errors='replace') as f:
            for line in f:
                if f"[{match_type}]" in line:
                    match = re.search(rf"\[{match_type}\]\s+(.*?)\s+:", line)
                    if match:
                        tag = match.group(1).strip()
                        main_tag= strip_main(tag)
                        if tag != main_tag:
                            feature_mapping[tag] = main_tag
                            
            if not feature_mapping:
                print("âš ï¸ æ²’æœ‰å¾ log ä¸­åµæ¸¬åˆ°æœ‰æ•ˆçš„å­åŠŸèƒ½å°æ‡‰")

            return feature_mapping

    # å¤–éƒ¨å‚³å…¥
    elif isinstance(predefined_mapping, dict):
        return predefined_mapping

    else:
        print("â— ç„¡æ•ˆçš„ feature_mapping_style æˆ– mapping æ ¼å¼")
        return {}

def strip_main(tag,choose="main_tag"): 
    if "-" in tag:
        split_pos = tag.rfind("-")
        main_tag = tag[:split_pos].strip()
        sub_tag = tag[split_pos + 1:].strip()
    else:
        main_tag = tag
        sub_tag = tag

    if choose=="main_tag":
        return main_tag
    else:
        return sub_tag

if not os.path.exists("documentary"):
    os.mkdir("documentary") 




# ç®¡ç†æ±ºå®šè³‡æ–™æ˜¯å¦é¡¯ç¤ºåœ¨çµ‚ç«¯æ©Ÿ
class PrintManager:
    LEVEL_PRIORITY = {
        "all": -1,     # é¡¯ç¤ºæ‰€æœ‰è¼¸å‡º
        "info": 0,     # æœ€åŸºæœ¬å±¤ç´š
        "data": 1,
        "warning": 2,
        "error": 3,
        "off": 99      # é—œé–‰æ‰€æœ‰è¼¸å‡º
    }
    LEVEL_ICON = {
        "info":     "âšª ",
        "data":     "ğŸ”µ ",
        "warning":  "ğŸŸ  ",
        "error":    "ğŸ”´ ",
    }

    def __init__(self, mode="all", prefix=""):
        if mode not in self.LEVEL_PRIORITY:
            print(f"âš ï¸  ç„¡æ•ˆçš„ Print_Funct è¨­å®šï¼š{mode}ï¼Œè‡ªå‹•æ”¹ç‚º 'off'")
            mode = "off"
        self.mode = mode
        self.prefix = prefix

    def print_level_handle(self, *args, level="info", text=None):
            text = text if text is not None else " ".join(str(a) for a in args)
            text = str(text).strip()
            if level not in self.LEVEL_PRIORITY:
                print(f"âš ï¸  è­¦å‘Š,æœ‰ç„¡æ•ˆçš„ level è¨­å®šï¼š{level}")
            # åœ–æ¨™è™•ç†
            icon = self.LEVEL_ICON.get(level, "")
            full_msg = f"{icon}{self.prefix}{text}"
            msg_priority = self.LEVEL_PRIORITY.get(level, 0)
            mode_priority = self.LEVEL_PRIORITY.get(self.mode, 99)

            # error æ°¸é å°å‡º
            #print("mode_priority=",mode_priority,"\tmsg_priority=",msg_priority)
            if level == "error" or  mode_priority<=msg_priority :
                print(full_msg)


#å¤šåŸ·è¡Œç·’ç®¡ç†
class ResourceMonitor:
    def __init__(self, tag, proc, fps=5):
        self.tag = tag                  
        self.proc = proc
        self.interval = 1 / fps
        self.samples_cpu = []
        self.samples_mem = []
        self.running = False                    # æ˜¯å¦è¦é€²è¡Œç›£æ§
        self.thread = None                       

    def _collect(self):
        while self.running:
            cpu_val = self.proc.cpu_percent(interval=self.interval) # å–å¾— CPU ç›®å‰è³‡æºä½¿ç”¨é‡
            mem_val = self.proc.memory_info().rss                   # å–å¾—è¨˜æ†¶é«”ç›®å‰è³‡æºä½¿ç”¨é‡
            self.samples_cpu.append(cpu_val)
            self.samples_mem.append(mem_val)

    def start(self):
        self.running = True                         #é–‹å•Ÿè³‡æºç›£æ§
        self.thread = Thread(target=self._collect)
        self.thread.start()


    def stop(self):
        self.running = False
        self.thread.join()
        return self.samples_cpu, self.samples_mem


    


# å®šç¾© Log é¡åˆ¥
class Log:

    # æŠŠå…è¨±å¯«å…¥ log çš„æ–¹æ³•å­˜åœ¨ config ä¸­ choose[all,log,data_size,data_time,data_message,data_content,else_info]
    def __init__(self, choose=["all"], Print_Funct="all", Auto_Clear=False , File_Only=False, File_Name="log"):
        
        # å»ºç«‹ logger å¯¦é«”èˆ‡åç¨±
        logger_name = f"Logger_{File_Name.replace('/', '_')}"
        self.logger = logging.getLogger(logger_name)
        self.logger.setLevel(logging.INFO)

        # æ¸…é™¤é‡è¤‡ handlerï¼ˆé¿å…é‡è¤‡ logï¼‰
        if self.logger.handlers:
            self.logger.handlers.clear()

        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
        self._config = set(choose)

        # è¨­å®šè¼¸å‡ºåˆ°çµ‚ç«¯æ©Ÿæ¬Šé™
        self.Print_funct = Print_Funct
        self.printer = PrintManager(mode=Print_Funct, prefix="[Log]\t")
        self.logprint = self.printer.print_level_handle
        self.logprint(f"Log choose ä»¥è¨­å®š: {self._config}")

        # è¨­å®š log æª”æ˜¯å¦è¦ä¾ç…§æ¯å°æ™‚æ™‚é–“å‘½åé‚„æ˜¯ç›´æ¥å¯«å…¥åœ¨æŒ‡å®šçš„æª”æ¡ˆ
        if(File_Only):
            log_filename=f"./documentary/{File_Name}.log"
        else:
            # è¨­å®š log æª”åï¼ˆä»¥å¹´æœˆæ—¥_å°æ™‚ï¼‰æ ¼å¼
            now = datetime.now().strftime("%Y%m%d_%H")
            log_filename = f"./documentary/log_{now}.log"

        # è¨­å®šæ˜¯å¦è¦è¤‡å¯«æª”æ¡ˆé‚„æ˜¯ç¹¼çºŒæ¥è‘—å¯«
        if(Auto_Clear):
            handler = logging.FileHandler(log_filename, mode='w',encoding='utf-8-sig')
            self.logprint(f"å·²æ¸…ç©º{log_filename}çš„æª”æ¡ˆ")
        else:
            handler = logging.FileHandler(log_filename,encoding='utf-8-sig')
            self.logprint(f"æ–°å¢åˆ°{log_filename}çš„æª”æ¡ˆ")

        # è¨­å®š formatter ä¸¦æ›ä¸Š handler
        handler.setFormatter(formatter)
        self.logger.addHandler(handler)


    #   data:å¤§å°  ,data_type:è³‡æ–™çš„é¡åˆ¥   ,message:æ˜¯å“ªå€‹è³‡æ–™æµçš„å¤§å°
    def data_size(self, data, message="", data_type="",root_config_enable=False):
        if "all" in self._config or "log" in self._config or root_config_enable or "data_size" in self._config:
            
            if data_type!="":
                data_type=f"[{data_type}]"

            self.logger.info(f"[Data Size] {data_type} {message} : {data}")
            self.logprint(level="data",text=f"data_size å¯«å…¥->\t{data_type} {message} : {data}")

    #   data:æ™‚é–“  ,unit:æ™‚é–“å–®ä½(é è¨­ç‚ºå¾®ç§’)  ,message:æ˜¯å“ªå€‹è³‡æ–™æµçš„æ™‚é–“
    def data_time(self, data, message="", unit="s",root_config_enable=False):                 
        if "all" in self._config or "log" in self._config or root_config_enable or "data_time" in self._config:
            self.logger.info(f"[Data Time]  {message} : {data:.7f}{unit}")
            self.logprint(level="data",text=f"data_time å¯«å…¥->\t{message} : {data}{unit}")

    #   message:æƒ³å¯«å…¥çš„è³‡è¨Šæˆ–è¨Šæ¯
    def data_message(self, message):
        if "all" in self._config or "log" in self._config or "data_message" in self._config:
            self.logger.info(message)
            self.logprint(level="data",text=f"message å¯«å…¥->\t{message}")
    
    #   data:æƒ³å¯«å…¥çš„è³‡æ–™å…§å®¹  ,num_limit:é™åˆ¶å­—æ•¸çš„æ•¸é‡
    def data_content(self, data, num_limit=None):
        if "all" in self._config or "log" in self._config or "data_content" in self._config:
            if isinstance(num_limit, int) and num_limit >= 0:
                # åƒ…å°å¯åˆ‡å‰²å‹åˆ¥åšæˆªæ–·
                if isinstance(data, (str, list, tuple)):
                    data = data[:num_limit]
                else:
                    self.logprint(level="warning", text=f"<data_content> !!! ç„¡æ³•å° {type(data).__name__} åšæˆªæ–·ï¼Œå°‡å®Œæ•´å¯«å…¥ !!!")

            elif num_limit is not None:
                # num_limit ä¸æ˜¯æ•¸å­—
                self.logprint(level="warning", text=f"<data_content> !!! num_limit å¿…é ˆæ˜¯éè² æ•´æ•¸ï¼Œå¿½ç•¥é™åˆ¶ !!!")

            # æœ€çµ‚ä¸è«–å‹åˆ¥ï¼Œéƒ½å¯«å…¥ log
            self.logger.info(data)
            self.logprint(level="data", text=f"content å¯«å…¥->\t{data}")
                
    #æŠ“å–ç›®å‰ç¨‹å¼çš„ CPU% èˆ‡è¨˜æ†¶é«” RSSï¼Œä¸¦å¯«å…¥ log
    def data_resource_usage(self, data_type="", Memory_unit="MB", choose=["CPU", "Memory"], Use_multi_core=False,Use_during=False, tag="", override_values=None):
        cpu_estimated   = override_values.get("cpu_estimated")    if override_values else None
        memory          = override_values.get("memory")       if override_values else None
        core_num  = override_values.get("core")         if override_values else psutil.cpu_count(logical=True)
        CPU_during= override_values.get("CPU_during")   if override_values else ""
        Memory_during= override_values.get("Memory_during")   if override_values else ""
        FPS = override_values.get("FPS")   if override_values else 1

        if "all" in self._config or "log" in self._config or "data_resource_usage" in self._config:
            if "CPU" in choose and cpu_estimated is not None:
                if Use_multi_core:
                    write_cpu_type="Multi_core CPU (mean)"
                    write_cpu_core=f"(Used {core_num} cores)"
                else:
                    write_cpu_type="CPU (mean)"
                    write_cpu_core=""

                if Use_during:
                    write_cpu_during=f"\nCPU During : {CPU_during} FPS={FPS}"
                else:
                    write_cpu_during=""

                
                self.logger.info(f"[{write_cpu_type}] {data_type} {tag} : {cpu_estimated}% {write_cpu_core} {write_cpu_during}")
                self.logprint(level="data",text=f"data_resource_usage å¯«å…¥->\t[{write_cpu_type}] {data_type} {tag} : {cpu_estimated}% {write_cpu_core} {write_cpu_during}")
                

            if "Memory" in choose and memory is not None:
                if Use_during:
                    write_Memory_during=f"\nMemory During : {Memory_during} FPS={FPS}"
                else:
                    write_Memory_during=""

                self.logger.info(f"[Memory] {data_type} {tag} : {memory}{Memory_unit} {write_Memory_during}")
                self.logprint(level="data", text=f"data_resource_usage å¯«å…¥->\t[Memory] {data_type} {tag} : {memory}{Memory_unit} {write_Memory_during}")

    def else_info(self, data,info_type, data_type="", message="", unit=""):
        if "all" in self._config or "log" in self._config or "else_info" in self._config:
            self.logger.info(f"[{info_type}] {data_type} {message} : {data}{unit}")
            self.logprint(level="data",text=f"else info å¯«å…¥->\t[{info_type}] {data_type} {message} : {data}{unit}")


class CodeTimer:
    
    def __init__(self,choose=["all"], Print_Funct="all"):

        self.start_times = {}
        self.records = [] 
        self._config = set(choose)

        # è¨­å®šè¼¸å‡ºåˆ°çµ‚ç«¯æ©Ÿæ¬Šé™
        self.Print_funct = Print_Funct
        self.printer = PrintManager(mode=Print_Funct, prefix="[CodeTimer]\t")
        self.Timerprint = self.printer.print_level_handle
        self.Timerprint(f"CodeTimer choose ä»¥è¨­å®š: {self._config}")

    def start(self, tag,group=""):
        if group!="":
            tag=f"{group}-{tag}"
        self.start_times[tag] = time.perf_counter()
        
    def stop(self, tag, size=None):
        if tag in self.start_times:
            end = time.perf_counter()
            elapsed = end - self.start_times[tag]
            self.records.append({
                'tag': tag,
                'start': self.start_times[tag],
                'end': end,
                'duration': elapsed,
                'size': size
            })
            return elapsed
        else:
            self.Timerprint(level="warning",text=f" !!! æœªå»ºç«‹{tag} starttime ç¯€é»æ¨™ç±¤ !!!")
            return None
    
    
    def generate_timeline_plot(self, file_name="",refresh=True,size_off=False):
        if  "all" in self._config or "timeline" in self._config:
            max_records = 100
            records = self.records[:max_records]

            if not records:
                self.Timerprint(level="error",text=" !!! æ²’æœ‰ä»»ä½•æ™‚é–“ç´€éŒ„ !!!")
                return
            
            if  len(records)>max_records:
                self.Timerprint(level="warning",text=" !!! è¨˜éŒ„çš„è³‡æ–™å¤ªå¤š,åªä¿ç•™å‰100å€‹è³‡æ–™ !!!")

            if file_name=="":
                now = datetime.now().strftime("%Y%m%d_%H")
                save_path = f"./documentary/timeline_{now}.png"
            else:
                save_path = f"./documentary/{file_name}.png"
            
            tag_records = defaultdict(list)
            for rec in records:
                tag_records[rec['tag']].append(rec)

            # ç‚ºæ¯å€‹ tag åˆ†é…ä¸€æ¢ y è»¸ä½ç½®
            tag_y_map = {tag: i for i, tag in enumerate(tag_records.keys())}

            fig, ax = plt.subplots(figsize=(10, len(tag_y_map) * 0.6))
            for tag, rec_list in tag_records.items():
                y_pos = tag_y_map[tag]
                for rec in rec_list:
                    start = rec['start'] - records[0]['start']
                    duration = rec['duration']
                    end = rec['end'] - records[0]['start']
                    size= rec['size']
                    ax.broken_barh([(start, duration)], (y_pos - 0.2, 0.4), facecolors='skyblue')
                    ax.text(start + duration / 2, y_pos, f"{duration:.2f}s", ha='center', va='center', fontsize=8)
                    if not size_off:
                        ax.text(end+0.25 , y_pos+ 0.25, f"{size}B", ha='right', va='bottom', fontsize=8)
            ax.set_yticks(range(len(tag_y_map)))
            ax.set_yticklabels(tag_y_map.keys())
            ax.set_xlabel("Time (s)")
            if size_off:
                ax.set_title("ç³»çµ±æ™‚åºåœ–ï¼šè™•ç†éšæ®µè€—æ™‚")
            else:
                ax.set_title("ç³»çµ±æ™‚åºåœ–ï¼šè™•ç†éšæ®µè€—æ™‚èˆ‡è³‡æ–™å¤§å°")
            ax.grid(True, axis='x')
            plt.tight_layout()
            plt.savefig(save_path)
            self.Timerprint(f"âœ… å·²ç”¢ç”Ÿæ™‚åºåœ–{save_path}")
            if refresh:
                self.records.clear()
                self.Timerprint("âœ… records å·²æ¸…ç©º")
        else:
            self.Timerprint("æœªå•Ÿå‹• generate_timeline_plot")
            return


    def Function_duration(self, log_name="", file_name="", feature_mapping=None,feature_mapping_style="auto",
                             size_off=False, title="",detail_timestamp=False, Sorting_method="time_length",
                             detail_timestamp_same_color=False,tick_interval=None,limit_longtime=None):
        
        if "all" in self._config or "Function_duration" in self._config:
            
            # è¨­å®š log æª”è·¯å¾‘
            if log_name == "":
                now = datetime.now().strftime("%Y%m%d_%H")
                log_path = f"./documentary/log_{now}.log"
            else:
                log_path = f"./documentary/{log_name}.log"

            # æª¢æŸ¥ log è·¯å¾‘æ˜¯å¦å­˜åœ¨
            if not os.path.exists(log_path):
                self.Timerprint(level="error",text=f" !!! ä¸å­˜åœ¨ {log_path} !!!")
                return
            else:
                self.Timerprint(f"åˆ†æ: {log_path}")

            # æ±ºå®šå„²å­˜è·¯å¾‘
            if not file_name:
                now = datetime.now().strftime("%Y%m%d_%H")
                save_path = f"./documentary/function_time_{now}.png"
            else:
                save_path = f"./documentary/{file_name}.png"

            # æ¨™é¡Œè¨­å®š
            if title == "":
                title = "å„é …åŠŸèƒ½ç¸½è€—æ™‚" if size_off else "å„é …åŠŸèƒ½ç¸½è€—æ™‚èˆ‡è³‡æ–™å¤§å°"

            # é¿å…åœ¨æ²’å•Ÿç”¨ detail_timestamp åŠŸèƒ½èª¤ç”¨äº† detail_timestamp_same_color åŠŸèƒ½
            if (not detail_timestamp) and detail_timestamp_same_color:
                detail_timestamp_same_color=False
                self.Timerprint(level="warning",text=" <Function_duration> æœªå•Ÿç”¨ detail_timestamp -> é—œé–‰ detail_timestamp_same_color åŠŸèƒ½")

            # åŠŸèƒ½å°æ‡‰è¡¨
            if feature_mapping==None:
                feature_mapping = build_feature_mapping_from_log(
                    log_path, feature_mapping_style, match_type="Data Size", predefined_mapping=feature_mapping
                )

            feature_mapping_list = set(feature_mapping.values())
            if not feature_mapping_list:
                self.Timerprint(level="error",text=f"âš ï¸ ç„¡æœ‰æ•ˆçš„ feature_mapping,ç„¡è³‡æ–™ç¹ªåœ–")
                return
            else:
                self.Timerprint(f"feature_mapping_list: {feature_mapping_list}")

            # çµ±è¨ˆçµæ§‹
            time_summary = defaultdict(float)                           
            size_summary = defaultdict(float)                           
            sub_time_summary = defaultdict(lambda: defaultdict(float))  # å­åŠŸèƒ½å°æ‡‰
            first_appearance_order = {}                                 # å„²å­˜ arrival time é †åº
            sub_feature_first_appearance_order = {}
            order_counter = 0
            sub_counter = 0

            # å–å¾—æ‰€æœ‰è³‡è¨Š
            with open(log_path, "r", encoding='utf-8-sig', errors='replace') as f:
                for line in f:
                    if "[Data Time]" in line:
                        match = re.search(r"\[Data Time\]\s+(.*?)\s+:\s+([\d.]+)", line)
                        if match:
                            tag = match.group(1).strip()
                            used_time = float(match.group(2))
                            main_tag = feature_mapping.get(tag, tag)
                            if main_tag in feature_mapping_list:
                                time_summary[main_tag] += used_time
                                sub_time_summary[main_tag][tag] += used_time

                                # æ’åºæ•´é«”åŠŸèƒ½å’Œå­åŠŸèƒ½çš„
                                if main_tag not in first_appearance_order:
                                    first_appearance_order[main_tag] = order_counter
                                    order_counter += 1
                                if tag not in sub_feature_first_appearance_order:
                                    sub_feature_first_appearance_order[tag] = sub_counter
                                    sub_counter += 1

                    elif "[Data Size]" in line:
                        match = re.search(r"\[Data Size\]\s+(.*?)\s+:\s+([\d.]+)", line)
                        if match:
                            tag = match.group(1).strip()
                            size = float(match.group(2))
                            main_tag = feature_mapping.get(tag, tag)
                            if main_tag in feature_mapping_list:
                                size_summary[main_tag] += size

            self.Timerprint(f"ğŸ“Š æ’åºæ–¹å¼: {Sorting_method}")
            
            

            # é€²è¡Œæ’åº
            if detail_timestamp:
                if Sorting_method == "arrival_time":
                    sorted_big = sorted(time_summary.items(), key=lambda x: first_appearance_order.get(x[0], float('inf')), reverse=True)
                else:
                    sorted_big = sorted(time_summary.items(), key=lambda x: x[1], reverse=True)

                big_labels = [k for k, _ in sorted_big]
                big_values = [list(sub_time_summary[k].values()) for k in big_labels]
                big_sublabels = [list(sub_time_summary[k].keys()) for k in big_labels]

                max_total_time = max(sum(v) for v in big_values)
                self.Timerprint(f"â±ï¸ æœ€å¤§ç¸½è€—æ™‚ï¼š{max_total_time:.2f} ç§’")

                if detail_timestamp_same_color:

                    stripped_tags = {strip_main(tag,"sub_tag") for tags in big_sublabels for tag in tags}

                    # æ’åºé †åºç”±é¦–æ¬¡å‡ºç¾çš„åŸå§‹ tag æ±ºå®š
                    def get_order(tag):
                        for full_tag in sub_feature_first_appearance_order:
                            if strip_main(full_tag,"sub_tag") == tag:
                                return sub_feature_first_appearance_order[full_tag]
                        return float('inf')

                    sorted_stripped = sorted(stripped_tags, key=get_order)
                    cmap = cm.get_cmap("tab20", len(sorted_stripped))
                    sub_colors = {tag: cmap(i) for i, tag in enumerate(sorted_stripped)}
                    colors = [[sub_colors[strip_main(tag,"sub_tag")] for tag in tags] for tags in big_sublabels]
                else:
                    all_sub = list({tag for tags in big_sublabels for tag in tags})
                    all_sub.sort(key=lambda tag: sub_feature_first_appearance_order.get(tag, float('inf')), reverse=True)
                    cmap = cm.get_cmap("tab20", len(all_sub))
                    sub_colors = {tag: cmap(i) for i, tag in enumerate(all_sub)}
                    colors = [[sub_colors[tag] for tag in tags] for tags in big_sublabels]

                plot_bar(big_labels, big_values, save_path, title=title, is_stacked=True, colors=colors, sub_colors=sub_colors,
                        data_sizes=size_summary,longest_time=max_total_time,tick_interval=tick_interval,fixed_xlim=limit_longtime,size_off=size_off)
            else:
                if Sorting_method == "arrival_time":
                    sorted_items = sorted(time_summary.items(), key=lambda x: first_appearance_order.get(x[0], float('inf')), reverse=True)
                else:
                    sorted_items = sorted(time_summary.items(), key=lambda x: x[1], reverse=True)

                labels, values = zip(*sorted_items)

                max_total_time = max(values)
                self.Timerprint(f"â±ï¸ æœ€å¤§ç¸½è€—æ™‚ï¼š{max_total_time:.2f} ç§’")

                cmap = cm.get_cmap("tab10", len(values))
                colors = [cmap(i) for i in range(len(values))]

                plot_bar(list(labels), list(values), save_path, title=title, is_stacked=False, colors=colors, data_sizes=size_summary,
                        longest_time=max_total_time,tick_interval=tick_interval,fixed_xlim=limit_longtime,size_off=size_off)

            self.Timerprint(f"âœ… å·²ç”¢ç”Ÿåœ– {save_path}")
        else:
            self.Timerprint("æœªå•Ÿå‹• Function_duration")
            return



class Analyze:
    def __init__(self,choose=["all"], Print_Funct="all",resource_choose=["CPU", "Memory"],Multi_core=False,Recording_process=False,memory_unit="MB",FPS=5):

        self._config = set(choose)

        # è¨­å®šè¼¸å‡ºåˆ°çµ‚ç«¯æ©Ÿæ¬Šé™
        self.Print_funct = Print_Funct
        self.printer = PrintManager(mode=Print_Funct, prefix="[Analyze]\t")
        self.Analyzeprint = self.printer.print_level_handle
        self.Analyzeprint(f"Analyze choose ä»¥è¨­å®š: {self._config}")

        # ç´€éŒ„ CPU å’Œ è¨˜æ†¶é«”è³‡æº
        self._resource_choose = resource_choose
        self._Multi_core = Multi_core
        self._memory_unit = memory_unit
        self._Recording_process =Recording_process
        self._FPS=FPS

        # å®£å‘Šæ‰€æœ‰ teg å­˜æ”¾
        self._active_resource_watches = {}

    def analyze_input(self,data):
        # å˜—è©¦æ˜¯ JSON å­—ä¸²
        if isinstance(data, str):
            try:
                parsed = json.loads(data)
                self.Analyzeprint(level="data",text=f"âœ… é€™æ˜¯ JSON å­—ä¸²")
                return "json", len(data.encode('utf-8'))
            except json.JSONDecodeError:
                self.Analyzeprint(level="data",text="âœ… é€™æ˜¯ç´”æ–‡å­—")
                return "text", len(data.encode('utf-8'))

        elif isinstance(data, dict) or isinstance(data, list):
            self.Analyzeprint(level="data",text="âœ… é€™æ˜¯å·²è§£æçš„ JSON çµæ§‹")
            return "json_dict", len(str(data).encode('utf-8'))

        elif isinstance(data, bytes):
            self.Analyzeprint(level="data",text="âœ… é€™æ˜¯äºŒé€²åˆ¶è³‡æ–™")
            return "binary", len(data)

        else:
            self.Analyzeprint(level="data",text="â“ ç„¡æ³•è¾¨è­˜")
            return "unknown", len(str(data).encode('utf-8'))
        
    def datasize_percent(self, log_name="", file_name="", feature_mapping=None,feature_mapping_style="auto",
                        label_type="DataSize (Byte)",Values_Visible=True,Percentage_Visible=True):
        if "all" in self._config or "datasize_percent" in self._config:
            
            # è¨­å®š log æª”è·¯å¾‘
            if log_name == "":
                now = datetime.now().strftime("%Y%m%d_%H")
                log_path = f"./documentary/log_{now}.log"
            else:
                log_path = f"./documentary/{log_name}.log"
            
            if not os.path.exists(log_path):
                self.Analyzeprint(level="error",text=f" !!! ä¸å­˜åœ¨æŒ‡å®šlogæª”è·¯å¾‘: {log_path} !!!")
                return
            else:
                self.Analyzeprint(f"åˆ†æ: {log_path}")

            # æ±ºå®šå„²å­˜è·¯å¾‘
            if not file_name:
                now = datetime.now().strftime("%Y%m%d_%H")
                save_path = f"./documentary/datasize_percent_{now}.png"
            else:
                save_path = f"./documentary/{file_name}.png"

            #  é è¨­åŠŸèƒ½å°æ‡‰è¡¨
            feature_mapping = build_feature_mapping_from_log(log_path,feature_mapping_style,match_type="Data Size", 
                                                             predefined_mapping=feature_mapping)
            
            size_summary = defaultdict(float)        
            feature_mapping_list = set(feature_mapping.values())
            if not feature_mapping_list:
                self.Analyzeprint(level="error",text=" !!! ç„¡æœ‰æ•ˆçš„ feature_mapping !!!")
                return
            else:
                self.Analyzeprint(f"feature_mapping_list: {feature_mapping_list}")

            with open(log_path, "r", encoding='utf-8-sig', errors='replace') as f:
                for line in f:
                    if "[Data Size]" in line:
                        match = re.search(r"\[Data Size\]\s+(.*?)\s+:\s+([\d.]+)", line)
                        if match:
                            tag = match.group(1).strip()
                            size = float(match.group(2))
                            main_tag = feature_mapping.get(tag, tag)
                            if main_tag in feature_mapping_list:
                                size_summary[main_tag] += size

            labels = list(size_summary.keys())
            values = list(size_summary.values())


            plot_pie(labels,values,save_path,title="å„é …åŠŸèƒ½çš„è³‡æ–™å¤§å°ç¸½å æ¯”",label_type=label_type,
                     emphasize_num=1,Values_Visible=Values_Visible,Percentage_Visible=Percentage_Visible)

    def start_resource_watch(self, tag):
        proc = psutil.Process(os.getpid())
        proc.cpu_percent(interval=None)                 # CPU ç´€éŒ„æ™‚è¦å…ˆæ¸…ç©ºä¹‹å‰çš„æ®˜é¤˜çš„åŸ·è¡Œç´€éŒ„ 
        monitor = ResourceMonitor(tag, proc, self._FPS)

        monitor.start()
        self._active_resource_watches[tag] = {
            "start_time": time.perf_counter(),
            "monitor": monitor,
            "multi_core": self._Multi_core,
            "memory_unit": self._memory_unit,
            "choose": self._resource_choose,
            "Recording_process": self._Recording_process,
            "FPS": self._FPS,
        }
        print("->start tag=\t",tag)
    

    def end_resource_watch(self, tag, log=None, data_type=""):
        if tag not in self._active_resource_watches:
            self.Analyzeprint(level="warning", text=f"!!! æœªå»ºç«‹{tag} start_resource_watch ç¯€é»æ¨™ç±¤ !!!")
            return
         
        watch = self._active_resource_watches.pop(tag)  # é–‹å§‹è³‡æºç›£æ§æ™‚çš„è³‡è¨Š
        end_time = time.perf_counter()              
        duration = end_time - watch["start_time"]       # å‚³å›ç›£æ§æ™‚é–“
        cores = psutil.cpu_count()                      # å–å¾—ç›®å‰è£ç½®çš„æ ¸å¿ƒæ•¸
       
        monitor = watch["monitor"]              # å–å¾—ç›£æ§è£ç½®
        unit = watch["memory_unit"]             # å–å¾—è¨˜æ†¶é«”å–®ä½
        samples_cpu, samples_mem = monitor.stop() if monitor else ([], [])  #å–å¾— monitor ç›£æ§æœŸé–“æ¯å€‹æ™‚é–“æ®µçš„è³‡è¨Š

        # --------- è¨˜æ†¶é«” ---------
        if samples_mem:  
            Memory_during = [mem / watch["FPS"] for mem in samples_mem]
            mem_estimated = round(sum(Memory_during) / Unit_conversion[unit], 3)
        else:
            mem_estimated = 0.0
        
        # --------- CPU ---------
        cpu_raw = round(sum(samples_cpu) / len(samples_cpu), 3) if samples_cpu else 0.0
        cpu_share = round((cpu_raw / (100 * cores)) * 100, 3) if samples_cpu else 0.0

        # --------- CPU During Log ---------
        if watch["multi_core"]:                                            
            multi_core_sample = [round(s / cores, 3) for s in samples_cpu]
            CPU_during = f"{multi_core_sample}"
        else:
            CPU_during = f"{samples_cpu}"

        # --------- å¯«å…¥ Log ---------
        if log:
            log.data_resource_usage(
                tag            =tag,
                data_type      =data_type,
                Memory_unit    =unit,
                choose         =watch["choose"],
                Use_multi_core = watch["multi_core"],
                Use_during     =watch["Recording_process"],
                override_values={
                    "cpu_estimated":cpu_share if watch.get("multi_core") else cpu_raw,
                    "memory": mem_estimated,
                    "core": cores,
                    "FPS": watch["FPS"],
                    "CPU_during": CPU_during if watch.get("Recording_process") else None,
                    "Memory_during":Memory_during if watch.get("Recording_process") else None,
                }
            )

        self.Analyzeprint(level="data",text=f"ğŸ“ˆ CPU: {cpu_raw}% ,Memory: {mem_estimated} MB, Time: {duration:.2f}s")
        print("->end tag=\t",tag)
        return duration, cpu_raw, cpu_share, mem_estimated


    def hourly_time_flow(
        self,
        log_path: str,
        start_time: datetime,
        end_time: datetime,
        save_path: str = "./hourly_function_time.png",
        tag_filter: list = None  # åŠ å…¥é€™å€‹åƒæ•¸ï¼Œæ”¯æ´åŠŸèƒ½éæ¿¾
    ):
        """
        è®€å–å–®ä¸€ log æª”æ¡ˆï¼ˆåŒ…å« [Data Time]ï¼‰ï¼Œä¾æ“šæ™‚é–“ç¯„åœèˆ‡æ¯å°æ™‚ï¼Œçµ±è¨ˆå„åŠŸèƒ½ç¸½è€—æ™‚ï¼Œç•«å‡ºæŠ˜ç·šåœ–ã€‚

        Parameters:
        - log_path: str â†’ log æª”æ¡ˆè·¯å¾‘
        - start_time: datetime â†’ åªåˆ†æè©²æ™‚é–“ä»¥å¾Œçš„ log
        - end_time: datetime â†’ åªåˆ†æè©²æ™‚é–“ä»¥å‰çš„ log
        - save_path: str â†’ åœ–ç‰‡å„²å­˜è·¯å¾‘
        - tag_filter: list â†’ é™å®šè¦ç•«çš„åŠŸèƒ½åç¨±ï¼ˆé è¨­ None è¡¨ç¤ºå…¨ç•«ï¼‰
        """

        pattern = re.compile(
            r'^(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}),\d+\s+- INFO - \[Data Time\]\s+(.*?)\s+:\s+([\d.]+)s'
        )
        hourly_function_times = defaultdict(lambda: defaultdict(float))  # {hour -> {tag -> total_time}}
        function_totals = defaultdict(float)

        with open(log_path, encoding='utf-8') as f:
            for line in f:
                match = pattern.match(line)
                if match:
                    timestamp = datetime.strptime(match.group(1), "%Y-%m-%d %H:%M:%S")
                    if not (start_time <= timestamp <= end_time):
                        continue
                    tag = match.group(2).strip()
                    if tag_filter and tag not in tag_filter:
                        continue  # ä¸åœ¨ç¯©é¸æ¸…å–®ä¸­çš„å°±è·³é
                    duration = float(match.group(3))
                    hour = timestamp.replace(minute=0, second=0, microsecond=0)
                    hourly_function_times[hour][tag] += duration
                    function_totals[tag] += duration

        # æ•´ç†è³‡æ–™
        hours = sorted(hourly_function_times.keys())
        all_tags = sorted(set(tag for tags in hourly_function_times.values() for tag in tags))
        data_dict = {
            tag: [hourly_function_times[hour].get(tag, 0) for hour in hours]
            for tag in all_tags
        }

        # èª¿ç”¨é€šç”¨æŠ˜ç·šåœ–ç¹ªè£½å‡½æ•¸
        plot_multiline_timeseries(
            time_index=hours,
            data_dict=data_dict,
            save_path=save_path,
            title="Total execution time when calculating risk",
            xlabel="Time",
            ylabel="Execution time (s)",
            font_config=None  # æˆ–ç”¨ Default_font
        )

        return dict(function_totals)

    def plot_resource_distribution(
        self,
        log_path: str,
        save_path: str = "./resource_dist.png",
        metric: str = "both",                   # "cpu" / "mem" / "both"
        top_n: int = None,                      # åƒ…é¡¯ç¤ºå‰ N åï¼Œå…¶é¤˜åˆä½µç‚º "Other"
        memory_display_unit: str="keep",        # æ˜¯å¦å°è¨˜æ†¶é«”åšå–®ä½è½‰æ›(keep è¡¨ç¤ºæ¡ç”¨logè£¡çš„å–®ä½)      
        feature_mapping: dict = None,
        font_config: dict = None,
        show_percent: bool = True,
                     
    ):
        def merge_by_feature_mapping(data_dict, mapping):
            merged = defaultdict(float)
            for tag, value in data_dict.items():
                # ç”¨ mapping æŠŠ tag è½‰æˆä¸»åŠŸèƒ½
                main_tag = mapping.get(tag, tag)
                merged[main_tag] += value
            return dict(merged)

        if not os.path.exists(log_path):
            self.Analyzeprint(level="error",text=f"<plot_resource_distribution> !!! log not found: {log_path}")
            return
        

        cpu_pat = re.compile(r"\[CPU \(mean\)\]\s+(.*?)\s+:\s+([\d.]+)%")
        mem_pat = re.compile(r"\[Memory\]\s+(.*?)\s+:\s+([\d.]+)\s*([A-Za-z]+)")
        
        cpu_dict, mem_dict = defaultdict(float), defaultdict(float)

        with open(log_path, encoding="utf-8") as f:
            for line in f:
                # CPU å€
                match = cpu_pat.search(line)
                if match:
                    tag = match.group(1)
                    cpu_val = float(match.group(2))
                    cpu_dict[tag] += cpu_val
                # è¨˜æ†¶é«”å€
                match = mem_pat.search(line)
                if match:
                    tag = match.group(1)
                    num_val  = float(match.group(2))
                    unit = match.group(3)
                    mem_dict[tag] += num_val   
                
                    
        if not cpu_dict and not mem_dict:
            self.Analyzeprint(level="error",text="<plot_resource_distribution> æ²’æŠ“åˆ°ä»»ä½•è³‡æºç´€éŒ„")
            return

        cfg = {**Default_font, **(font_config or {})}
        if feature_mapping:
            cpu_dict = merge_by_feature_mapping(cpu_dict, feature_mapping)
            mem_dict = merge_by_feature_mapping(mem_dict, feature_mapping)\
            
        def _aggregate(d: dict):
            """ä¾ top_n å° dict åš other åˆä½µä¸¦å›å‚³ labels & values"""
            if not top_n or len(d) <= top_n:
                return list(d.keys()), list(d.values())

            sorted_items = sorted(d.items(), key=lambda x: x[1], reverse=True)
            kept = sorted_items[:top_n]
            other_sum = sum(v for _, v in sorted_items[top_n:])
            labels = [k for k, _ in kept] + ["Other"]
            values = [v for _, v in kept] + [other_sum]
            return labels, values

        

        # --------- CPU ----------
        if metric.lower() in ("cpu", "both") and cpu_dict:
            lbl, val = _aggregate(cpu_dict)
            cpu_path = save_path if metric == "cpu" else save_path.replace(".png", "_CPU.png")
            plot_pie(
                labels=lbl,
                values=val,
                save_path=cpu_path,
                title="CPU usage",
                label_type="CPU (%)",
                font_config=cfg,
                emphasize_num=1,
                Values_Visible=False,
                Percentage_Visible=show_percent
            )
            self.Analyzeprint(f"âœ… å·²ç”¢ç”Ÿåœ– {cpu_path}")


        # --------- Memory ----------
        if metric.lower() in ("mem", "both") and mem_dict:
            if memory_display_unit != "keep":
                divisor = Unit_conversion[unit]/Unit_conversion[memory_display_unit]
                mem_dict = {k: round(v * divisor,3) for k, v in mem_dict.items()}
                unit = memory_display_unit  # ç”¨æŒ‡å®šå–®ä½é¡¯ç¤º

            lbl, val = _aggregate(mem_dict)
            mem_path = save_path if metric == "mem" else save_path.replace(".png", "_Memory.png")
            plot_pie(
                labels=lbl,
                values=val,
                save_path=mem_path,
                title="Memory usage",
                label_type=f"Memory ({unit})",
                font_config=cfg,
                emphasize_num=1,
                Values_Visible=True,
                Percentage_Visible=show_percent
            )
            self.Analyzeprint(f"âœ… å·²ç”¢ç”Ÿåœ– {mem_path}")
            

# === Helper function forå¿«é€ŸçµæŸä¸¦è¨˜éŒ„ === (çµåˆlogæ™‚é–“ã€å¤§å°ç´€éŒ„ + æ™‚é–“stopç¯€é») 
def timer_stop_log(tag,group="",size=None, content="", timer=None, log=None):
    """
    è‡ªå‹•åœæ­¢è¨ˆæ™‚ä¸¦è¨˜éŒ„è€—æ™‚èˆ‡è³‡æ–™å¤§å°

    :param tag: è¨˜éŒ„çš„æ¨™ç±¤åç¨±
    :param content: è¦åˆ†æå¤§å°çš„è³‡æ–™
    :param timer: CodeTimer å¯¦ä¾‹
    :param log: Log å¯¦ä¾‹
    """

    if timer is None or log is None:
        print("â—è«‹å‚³å…¥ timer èˆ‡ log å¯¦ä¾‹")
        return
    if size==None:
        size_content=len(str(content).encode('utf-8'))
    else:
        size_content=size

    if group!="":
        tag=f"{group}-{tag}"

    elapsed = timer.stop(tag, size=size_content)
    log.data_time(elapsed, message=tag,root_config_enable=True)
    log.data_size(size_content, message=tag,root_config_enable=True)
    return elapsed



"""
def plot_hourly_function_time_trend(log_dir="./documentary", save_path="./documentary/hourly_function_time.png"):
    pattern = re.compile(r'\[Data Time\]\s+(.*?)\s+:\s+([\d.]+)')
    hourly_data = defaultdict(lambda: defaultdict(float))  # {hour -> {tag -> total_time}}

    log_files = sorted(glob.glob(os.path.join(log_dir, "log_*.log")))

    for file_path in log_files:
        match_hour = re.search(r"log_(\d{8}_\d{2})\.log", os.path.basename(file_path))
        if not match_hour:
            continue
        hour_str = match_hour.group(1)
        hour_time = datetime.strptime(hour_str, "%Y%m%d_%H")

        with open(file_path, "r", encoding='big5', errors='replace') as f:
            for line in f:
                match = pattern.search(line)
                if match:
                    tag = match.group(1).strip()
                    duration = float(match.group(2))
                    hourly_data[hour_time][tag] += duration

    if not hourly_data:
        print("â— æ²’æœ‰æ‰¾åˆ°ä»»ä½•ç¬¦åˆçš„ log æª”æ¡ˆ")
        return

    # ç¢ºå®šæ‰€æœ‰åŠŸèƒ½åç¨±
    all_tags = set()
    for tag_data in hourly_data.values():
        all_tags.update(tag_data.keys())
    all_tags = sorted(all_tags)

    # å°‡æ™‚é–“èˆ‡è³‡æ–™è½‰ç‚ºåœ–è¡¨æ ¼å¼
    times = sorted(hourly_data.keys())
    plot_data = {tag: [] for tag in all_tags}

    for t in times:
        for tag in all_tags:
            plot_data[tag].append(hourly_data[t].get(tag, 0))

    # ç•«åœ–
    plt.figure(figsize=(12, 6))
    for tag in all_tags:
        plt.plot(times, plot_data[tag], label=tag)

    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%m-%d %H:%M'))
    plt.gca().xaxis.set_major_locator(mdates.HourLocator(interval=1))
    plt.gcf().autofmt_xdate()

    plt.title("æ¯å°æ™‚å„åŠŸèƒ½ç¸½è€—æ™‚è¶¨å‹¢")
    plt.xlabel("æ™‚é–“")
    plt.ylabel("è€—æ™‚ï¼ˆç§’ï¼‰")
    plt.legend(loc="upper left", bbox_to_anchor=(1, 1))
    plt.tight_layout()
    plt.savefig(save_path, dpi=300)
    plt.close()
    print(f"âœ… æŠ˜ç·šåœ–å·²å„²å­˜è‡³ {save_path}")

"""